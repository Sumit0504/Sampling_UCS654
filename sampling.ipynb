{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "d = pd.read_csv('/Users/mac/Documents/Sampling/Creditcard_data.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = d.drop(columns=[\"Class\"])\n",
    "y = d[\"Class\"]\n",
    "\n",
    "# Apply SMOTE + Tomek Links for balancing\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X, y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_resampled = scaler.fit_transform(X_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling techniques\n",
    "def simple_random_sampling(X, y, size):\n",
    "    data = pd.DataFrame(X)\n",
    "    data['Class'] = y\n",
    "    return data.sample(n=size, random_state=42)\n",
    "\n",
    "def stratified_sampling(X, y, size):\n",
    "    data = pd.DataFrame(X)\n",
    "    data['Class'] = y\n",
    "    return resample(data, n_samples=size, stratify=y, random_state=42)\n",
    "\n",
    "def bootstrap_sampling(X, y, size):\n",
    "    data = pd.DataFrame(X)\n",
    "    data['Class'] = y\n",
    "    return data.sample(n=size, replace=True, random_state=42)\n",
    "\n",
    "def systematic_sampling(X, y, size):\n",
    "    data = pd.DataFrame(X)\n",
    "    data['Class'] = y\n",
    "    step = len(data) // size\n",
    "    return data.iloc[::step]\n",
    "\n",
    "def cluster_sampling(X, y, size):\n",
    "    data = pd.DataFrame(X)\n",
    "    data['Class'] = y\n",
    "    kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "    data['Cluster'] = kmeans.fit_predict(X)\n",
    "    cluster_samples = []\n",
    "    for cluster_label in data['Cluster'].unique():\n",
    "        cluster_data = data[data['Cluster'] == cluster_label]\n",
    "        sample_count = min(len(cluster_data), size // 5)\n",
    "        cluster_samples.append(cluster_data.sample(n=sample_count, random_state=42))\n",
    "    sampled_data = pd.concat(cluster_samples).drop(columns=['Cluster'])\n",
    "    return sampled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models with tuned parameters\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    \"Support Vector Machine\": SVC(kernel='rbf', C=10, probability=True, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "}\n",
    "\n",
    "\n",
    "sampling_techniques = {\n",
    "    \"Simple Random Sampling\": simple_random_sampling,\n",
    "    \"Stratified Sampling\": stratified_sampling,\n",
    "    \"Bootstrap Sampling\": bootstrap_sampling,\n",
    "    \"Systematic Sampling\": systematic_sampling,\n",
    "    \"Cluster Sampling\": cluster_sampling,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Sample Size: 305\n",
      "Accuracy Matrix:\n",
      "                        Logistic Regression  Decision Tree  \\\n",
      "Simple Random Sampling             0.815217       0.956522   \n",
      "Stratified Sampling                0.923913       0.934783   \n",
      "Bootstrap Sampling                 0.913043       0.956522   \n",
      "Systematic Sampling                0.848214       0.973214   \n",
      "Cluster Sampling                   0.935897       0.935897   \n",
      "\n",
      "                        Support Vector Machine  K-Nearest Neighbors  \\\n",
      "Simple Random Sampling                0.956522             0.869565   \n",
      "Stratified Sampling                   0.934783             0.804348   \n",
      "Bootstrap Sampling                    0.956522             0.869565   \n",
      "Systematic Sampling                   0.982143             0.910714   \n",
      "Cluster Sampling                      0.961538             0.884615   \n",
      "\n",
      "                        Random Forest  \n",
      "Simple Random Sampling       0.989130  \n",
      "Stratified Sampling          0.967391  \n",
      "Bootstrap Sampling           0.989130  \n",
      "Systematic Sampling          0.991071  \n",
      "Cluster Sampling             0.974359  \n",
      "\n",
      "Best Sampling Technique for Each Model:\n",
      "Logistic Regression          Cluster Sampling\n",
      "Decision Tree             Systematic Sampling\n",
      "Support Vector Machine    Systematic Sampling\n",
      "K-Nearest Neighbors       Systematic Sampling\n",
      "Random Forest             Systematic Sampling\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Determine sample size\n",
    "Z = 1.96  # Z-value for 95% confidence\n",
    "p = 0.5   # Estimated proportion\n",
    "E = 0.05  # Margin of error\n",
    "N = len(X_resampled)\n",
    "\n",
    "sample_size = int((Z**2 * p * (1 - p) * N) / (E**2 * (N - 1) + Z**2 * p * (1 - p)))\n",
    "print(f\"Calculated Sample Size: {sample_size}\")\n",
    "\n",
    "# Create samples\n",
    "samples = {}\n",
    "for technique_name, sampling_func in sampling_techniques.items():\n",
    "    samples[technique_name] = sampling_func(X_resampled, y_resampled, sample_size)\n",
    "\n",
    "# Train and evaluate models\n",
    "accuracy_matrix = {}\n",
    "for sample_name, sample_data in samples.items():\n",
    "    X_smpl = sample_data.drop(columns=[\"Class\"])\n",
    "    y_smpl = sample_data[\"Class\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_smpl, y_smpl, test_size=0.3, random_state=42)\n",
    "\n",
    "    accuracy_matrix[sample_name] = {}\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracy_matrix[sample_name][model_name] = accuracy\n",
    "\n",
    "# Display results\n",
    "accuracy_df = pd.DataFrame(accuracy_matrix).T\n",
    "print(\"Accuracy Matrix:\")\n",
    "print(accuracy_df)\n",
    "\n",
    "# Find the best sampling technique and model\n",
    "best_technique = accuracy_df.max(axis=1).idxmax()\n",
    "best_model = accuracy_df.loc[best_technique].idxmax()\n",
    "best_score = accuracy_df.loc[best_technique, best_model]\n",
    "\n",
    "\n",
    "# Find best sampling technique for each model\n",
    "best_combo = accuracy_df.idxmax()\n",
    "print(\"\\nBest Sampling Technique for Each Model:\")\n",
    "print(best_combo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Sampling Technique: Systematic Sampling\n",
      "Best Model: Random Forest\n",
      "Best Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nBest Sampling Technique: {best_technique}\")\n",
    "print(f\"Best Model: {best_model}\")\n",
    "\n",
    "print(f\"Best Accuracy: {best_score:.2f}\")\n",
    "\n",
    "\n",
    "accuracy_df.to_csv(\"sampling_results.csv\")\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
